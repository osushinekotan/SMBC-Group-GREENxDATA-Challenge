# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /cv: stratified_kfold
  - override /cat: "020"

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

experiment_name: ${hydra:job.override_dirname}
notebook: tabular_v3
debug: true

feature_store: "015"
cache_feature_extractors: false
overwrite_training: true

align_train_test: false
replace_rare_values_threshold: 0

transformer_model: microsoft/deberta-v3-small
max_length: 5

cv:
  n_splits: 2

train_args:
  _target_: transformers.TrainingArguments
  output_dir: null # will be set
  evaluation_strategy: "epoch"
  learning_rate: 0.0001
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  num_train_epochs: 4
  weight_decay: 0.01
  fp16: false
  save_total_limit: 1
  save_strategy: "epoch"
  metric_for_best_model: f1_score
  load_best_model_at_end: True
  greater_is_better: True
  seed: 42
